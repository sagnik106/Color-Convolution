{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Conv3D, Reshape, Activation, Dropout, Flatten\n",
    "from tensorflow.config.experimental import set_memory_growth, get_visible_devices\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Configuration\n",
    "(You can skip this part. It will not cause issues even if you do not have a CUDA enabled GPU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus=get_visible_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining general model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 160s 1us/step\nx_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\n"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n_________________________________________________________________\nactivation_9 (Activation)    (None, 30, 30, 32)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n_________________________________________________________________\nactivation_10 (Activation)   (None, 15, 15, 64)        0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n_________________________________________________________________\nactivation_11 (Activation)   (None, 13, 13, 64)        0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 6, 6, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2304)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               1180160   \n_________________________________________________________________\nactivation_12 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n_________________________________________________________________\nactivation_13 (Activation)   (None, 10)                0         \n=================================================================\nTotal params: 1,250,858\nTrainable params: 1,250,858\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "plot_model(model, \"resources/2d.png\", show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv3D(32, 3,\n",
    "                 input_shape=(32,32,3,1)))\n",
    "model1.add(Reshape((30,30,32)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(32, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(64, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(512))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(num_classes))\n",
    "model1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1 = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d_6 (Conv3D)            (None, 30, 30, 1, 32)     896       \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 30, 30, 32)        0         \n_________________________________________________________________\nactivation_24 (Activation)   (None, 30, 30, 32)        0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 28, 28, 32)        9248      \n_________________________________________________________________\nactivation_25 (Activation)   (None, 28, 28, 32)        0         \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 14, 14, 64)        18496     \n_________________________________________________________________\nactivation_26 (Activation)   (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 12, 12, 64)        36928     \n_________________________________________________________________\nactivation_27 (Activation)   (None, 12, 12, 64)        0         \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 6, 6, 64)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 2304)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               1180160   \n_________________________________________________________________\nactivation_28 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                5130      \n_________________________________________________________________\nactivation_29 (Activation)   (None, 10)                0         \n=================================================================\nTotal params: 1,250,858\nTrainable params: 1,250,858\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt1,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plot_model(model1, \"resources/3d.png\", show_shapes=True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Not using data augmentation.\nEpoch 1/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.8111 - accuracy: 0.3354 - val_loss: 1.5097 - val_accuracy: 0.4536\nEpoch 2/100\n1563/1563 [==============================] - 7s 5ms/step - loss: 1.4839 - accuracy: 0.4650 - val_loss: 1.3055 - val_accuracy: 0.5348\nEpoch 3/100\n1563/1563 [==============================] - 7s 5ms/step - loss: 1.3330 - accuracy: 0.5260 - val_loss: 1.3078 - val_accuracy: 0.5254\nEpoch 4/100\n1563/1563 [==============================] - 7s 5ms/step - loss: 1.2235 - accuracy: 0.5692 - val_loss: 1.1157 - val_accuracy: 0.6092\nEpoch 5/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.1500 - accuracy: 0.5964 - val_loss: 1.0401 - val_accuracy: 0.6381\nEpoch 6/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.0821 - accuracy: 0.6230 - val_loss: 1.0571 - val_accuracy: 0.6332\nEpoch 7/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.0337 - accuracy: 0.6385 - val_loss: 0.9543 - val_accuracy: 0.6636\nEpoch 8/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.9904 - accuracy: 0.6510 - val_loss: 0.9582 - val_accuracy: 0.6660\nEpoch 9/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.9511 - accuracy: 0.6672 - val_loss: 0.8874 - val_accuracy: 0.6904\nEpoch 10/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.9209 - accuracy: 0.6795 - val_loss: 0.8506 - val_accuracy: 0.7038\nEpoch 11/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.8918 - accuracy: 0.6893 - val_loss: 0.8710 - val_accuracy: 0.6945\nEpoch 12/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.8661 - accuracy: 0.6971 - val_loss: 0.8247 - val_accuracy: 0.7160\nEpoch 13/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.8473 - accuracy: 0.7084 - val_loss: 0.8056 - val_accuracy: 0.7213\nEpoch 14/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.8268 - accuracy: 0.7133 - val_loss: 0.8033 - val_accuracy: 0.7237\nEpoch 15/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.8128 - accuracy: 0.7192 - val_loss: 0.7803 - val_accuracy: 0.7311\nEpoch 16/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.7978 - accuracy: 0.7262 - val_loss: 0.7557 - val_accuracy: 0.7367\nEpoch 17/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.7824 - accuracy: 0.7301 - val_loss: 0.7716 - val_accuracy: 0.7360\nEpoch 18/100\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.7753 - accuracy: 0.7320 - val_loss: 0.7709 - val_accuracy: 0.7388\nEpoch 19/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7628 - accuracy: 0.7388 - val_loss: 0.7556 - val_accuracy: 0.7401\nEpoch 20/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7571 - accuracy: 0.7402 - val_loss: 0.7540 - val_accuracy: 0.7489\nEpoch 21/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7446 - accuracy: 0.7437 - val_loss: 0.7370 - val_accuracy: 0.7471\nEpoch 22/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7460 - accuracy: 0.7456 - val_loss: 0.7417 - val_accuracy: 0.7562\nEpoch 23/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7320 - accuracy: 0.7514 - val_loss: 0.7276 - val_accuracy: 0.7525\nEpoch 24/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7307 - accuracy: 0.7508 - val_loss: 0.7504 - val_accuracy: 0.7461\nEpoch 25/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7270 - accuracy: 0.7525 - val_loss: 0.6911 - val_accuracy: 0.7615\nEpoch 26/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7167 - accuracy: 0.7543 - val_loss: 0.7163 - val_accuracy: 0.7580\nEpoch 27/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7140 - accuracy: 0.7569 - val_loss: 0.7172 - val_accuracy: 0.7567\nEpoch 28/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7073 - accuracy: 0.7607 - val_loss: 0.7699 - val_accuracy: 0.7445\nEpoch 29/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7030 - accuracy: 0.7621 - val_loss: 0.7221 - val_accuracy: 0.7547\nEpoch 30/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7014 - accuracy: 0.7608 - val_loss: 0.6939 - val_accuracy: 0.7652\nEpoch 31/100\n1563/1563 [==============================] - 9s 5ms/step - loss: 0.6960 - accuracy: 0.7623 - val_loss: 0.7003 - val_accuracy: 0.7601\nEpoch 32/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6925 - accuracy: 0.7648 - val_loss: 0.6982 - val_accuracy: 0.7732\nEpoch 33/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.6885 - accuracy: 0.7653 - val_loss: 0.7022 - val_accuracy: 0.7651\nEpoch 34/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.6819 - accuracy: 0.7697 - val_loss: 0.7047 - val_accuracy: 0.7662\nEpoch 35/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6796 - accuracy: 0.7707 - val_loss: 0.6855 - val_accuracy: 0.7705\nEpoch 36/100\n1563/1563 [==============================] - 9s 5ms/step - loss: 0.6762 - accuracy: 0.7721 - val_loss: 0.7485 - val_accuracy: 0.7516\nEpoch 37/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6711 - accuracy: 0.7736 - val_loss: 0.6771 - val_accuracy: 0.7728\nEpoch 38/100\n1563/1563 [==============================] - 9s 5ms/step - loss: 0.6712 - accuracy: 0.7736 - val_loss: 0.6870 - val_accuracy: 0.7696\nEpoch 39/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6653 - accuracy: 0.7762 - val_loss: 0.7668 - val_accuracy: 0.7574\nEpoch 40/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.6627 - accuracy: 0.7760 - val_loss: 0.6618 - val_accuracy: 0.7791\nEpoch 41/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6587 - accuracy: 0.7777 - val_loss: 0.7084 - val_accuracy: 0.7694\nEpoch 42/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6547 - accuracy: 0.7795 - val_loss: 0.6793 - val_accuracy: 0.7697\nEpoch 43/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6506 - accuracy: 0.7809 - val_loss: 0.6848 - val_accuracy: 0.7842\nEpoch 44/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6552 - accuracy: 0.7807 - val_loss: 0.6573 - val_accuracy: 0.7799\nEpoch 45/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6538 - accuracy: 0.7806 - val_loss: 0.6792 - val_accuracy: 0.7750\nEpoch 46/100\n1563/1563 [==============================] - 12s 7ms/step - loss: 0.6480 - accuracy: 0.7827 - val_loss: 0.6737 - val_accuracy: 0.7754\nEpoch 47/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6504 - accuracy: 0.7834 - val_loss: 0.7049 - val_accuracy: 0.7746\nEpoch 48/100\n1563/1563 [==============================] - 12s 7ms/step - loss: 0.6430 - accuracy: 0.7841 - val_loss: 0.6903 - val_accuracy: 0.7720\nEpoch 49/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6448 - accuracy: 0.7846 - val_loss: 0.6745 - val_accuracy: 0.7759\nEpoch 50/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6446 - accuracy: 0.7829 - val_loss: 0.7258 - val_accuracy: 0.7726\nEpoch 51/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6393 - accuracy: 0.7871 - val_loss: 0.6663 - val_accuracy: 0.7791\nEpoch 52/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6373 - accuracy: 0.7854 - val_loss: 0.6669 - val_accuracy: 0.7795\nEpoch 53/100\n1563/1563 [==============================] - 12s 7ms/step - loss: 0.6359 - accuracy: 0.7887 - val_loss: 0.6639 - val_accuracy: 0.7811\nEpoch 54/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6359 - accuracy: 0.7851 - val_loss: 0.6549 - val_accuracy: 0.7872\nEpoch 55/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.6360 - accuracy: 0.7869 - val_loss: 0.6935 - val_accuracy: 0.7849\nEpoch 56/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6279 - accuracy: 0.7900 - val_loss: 0.7269 - val_accuracy: 0.7698\nEpoch 57/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6348 - accuracy: 0.7887 - val_loss: 0.6954 - val_accuracy: 0.7722\nEpoch 58/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6303 - accuracy: 0.7879 - val_loss: 0.6907 - val_accuracy: 0.7799\nEpoch 59/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6220 - accuracy: 0.7921 - val_loss: 0.6843 - val_accuracy: 0.7822\nEpoch 60/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6216 - accuracy: 0.7914 - val_loss: 0.6531 - val_accuracy: 0.7830\nEpoch 61/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6275 - accuracy: 0.7922 - val_loss: 0.7392 - val_accuracy: 0.7682\nEpoch 62/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6228 - accuracy: 0.7935 - val_loss: 0.6883 - val_accuracy: 0.7755\nEpoch 63/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6248 - accuracy: 0.7924 - val_loss: 0.6628 - val_accuracy: 0.7813\nEpoch 64/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6234 - accuracy: 0.7938 - val_loss: 0.6936 - val_accuracy: 0.7770\nEpoch 65/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6215 - accuracy: 0.7924 - val_loss: 0.6995 - val_accuracy: 0.7637\nEpoch 66/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6206 - accuracy: 0.7937 - val_loss: 0.6935 - val_accuracy: 0.7701\nEpoch 67/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6225 - accuracy: 0.7924 - val_loss: 0.7106 - val_accuracy: 0.7694\nEpoch 68/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6235 - accuracy: 0.7924 - val_loss: 0.6630 - val_accuracy: 0.7770\nEpoch 69/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6223 - accuracy: 0.7913 - val_loss: 0.6887 - val_accuracy: 0.7792\nEpoch 70/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6231 - accuracy: 0.7923 - val_loss: 0.6479 - val_accuracy: 0.7877\nEpoch 71/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6150 - accuracy: 0.7950 - val_loss: 0.7482 - val_accuracy: 0.7607\nEpoch 72/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6169 - accuracy: 0.7940 - val_loss: 0.6857 - val_accuracy: 0.7735\nEpoch 73/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6155 - accuracy: 0.7944 - val_loss: 0.7833 - val_accuracy: 0.7412\nEpoch 74/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6173 - accuracy: 0.7923 - val_loss: 0.6702 - val_accuracy: 0.7875\nEpoch 75/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6181 - accuracy: 0.7957 - val_loss: 0.6571 - val_accuracy: 0.7810\nEpoch 76/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6136 - accuracy: 0.7946 - val_loss: 0.7035 - val_accuracy: 0.7742\nEpoch 77/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6208 - accuracy: 0.7943 - val_loss: 0.6626 - val_accuracy: 0.7892\nEpoch 78/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6163 - accuracy: 0.7935 - val_loss: 0.7016 - val_accuracy: 0.7711\nEpoch 79/100\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.6135 - accuracy: 0.7943 - val_loss: 0.6891 - val_accuracy: 0.7805\nEpoch 80/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6177 - accuracy: 0.7954 - val_loss: 0.6626 - val_accuracy: 0.7780\nEpoch 81/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6171 - accuracy: 0.7932 - val_loss: 0.7322 - val_accuracy: 0.7886\nEpoch 82/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6169 - accuracy: 0.7949 - val_loss: 0.7184 - val_accuracy: 0.7725\nEpoch 83/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6135 - accuracy: 0.7952 - val_loss: 0.6709 - val_accuracy: 0.7771\nEpoch 84/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6051 - accuracy: 0.7965 - val_loss: 0.6674 - val_accuracy: 0.7806\nEpoch 85/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6110 - accuracy: 0.7974 - val_loss: 0.6705 - val_accuracy: 0.7767\nEpoch 86/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6187 - accuracy: 0.7942 - val_loss: 0.7942 - val_accuracy: 0.7581\nEpoch 87/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6161 - accuracy: 0.7974 - val_loss: 0.6990 - val_accuracy: 0.7769\nEpoch 88/100\n1563/1563 [==============================] - 12s 7ms/step - loss: 0.6147 - accuracy: 0.7947 - val_loss: 0.6637 - val_accuracy: 0.7834\nEpoch 89/100\n1563/1563 [==============================] - 12s 7ms/step - loss: 0.6182 - accuracy: 0.7944 - val_loss: 0.6718 - val_accuracy: 0.7808\nEpoch 90/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6168 - accuracy: 0.7970 - val_loss: 0.6738 - val_accuracy: 0.7744\nEpoch 91/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6163 - accuracy: 0.7957 - val_loss: 0.8057 - val_accuracy: 0.7444\nEpoch 92/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6162 - accuracy: 0.7976 - val_loss: 0.7733 - val_accuracy: 0.7648\nEpoch 93/100\n1563/1563 [==============================] - 12s 7ms/step - loss: 0.6161 - accuracy: 0.7968 - val_loss: 0.7696 - val_accuracy: 0.7485\nEpoch 94/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6086 - accuracy: 0.7964 - val_loss: 0.6643 - val_accuracy: 0.7797\nEpoch 95/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6194 - accuracy: 0.7950 - val_loss: 0.7490 - val_accuracy: 0.7661\nEpoch 96/100\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.6124 - accuracy: 0.7960 - val_loss: 0.7183 - val_accuracy: 0.7650\nEpoch 97/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6177 - accuracy: 0.7954 - val_loss: 0.6891 - val_accuracy: 0.7867\nEpoch 98/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6073 - accuracy: 0.7966 - val_loss: 0.7125 - val_accuracy: 0.7674\nEpoch 99/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6162 - accuracy: 0.7966 - val_loss: 0.7134 - val_accuracy: 0.7716\nEpoch 100/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6114 - accuracy: 0.7984 - val_loss: 0.7356 - val_accuracy: 0.7707\n"
    }
   ],
   "source": [
    "x_train=x_train.reshape((-1,32,32,3))\n",
    "x_test=x_test.reshape((-1,32,32,3))\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    h=model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "    datagen.fit(x_train)\n",
    "    h=model.fit(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),)\n",
    "h=h.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Not using data augmentation.\nEpoch 1/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.8285 - accuracy: 0.3276 - val_loss: 1.5933 - val_accuracy: 0.4246\nEpoch 2/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.5392 - accuracy: 0.4409 - val_loss: 1.3865 - val_accuracy: 0.4979\nEpoch 3/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.4065 - accuracy: 0.4951 - val_loss: 1.2805 - val_accuracy: 0.5414\nEpoch 4/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.2995 - accuracy: 0.5367 - val_loss: 1.1805 - val_accuracy: 0.5793\nEpoch 5/100\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.2165 - accuracy: 0.5687 - val_loss: 1.1221 - val_accuracy: 0.6054\nEpoch 6/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 1.1527 - accuracy: 0.5922 - val_loss: 1.0517 - val_accuracy: 0.6314\nEpoch 7/100\n1563/1563 [==============================] - 9s 5ms/step - loss: 1.0958 - accuracy: 0.6150 - val_loss: 1.0174 - val_accuracy: 0.6394\nEpoch 8/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 1.0464 - accuracy: 0.6307 - val_loss: 0.9953 - val_accuracy: 0.6475\nEpoch 9/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 1.0059 - accuracy: 0.6458 - val_loss: 0.9411 - val_accuracy: 0.6743\nEpoch 10/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.9707 - accuracy: 0.6595 - val_loss: 0.9095 - val_accuracy: 0.6866\nEpoch 11/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.9384 - accuracy: 0.6692 - val_loss: 0.9604 - val_accuracy: 0.6658\nEpoch 12/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.9096 - accuracy: 0.6808 - val_loss: 0.9274 - val_accuracy: 0.6811\nEpoch 13/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8820 - accuracy: 0.6934 - val_loss: 0.8290 - val_accuracy: 0.7159\nEpoch 14/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8596 - accuracy: 0.7013 - val_loss: 0.8077 - val_accuracy: 0.7188\nEpoch 15/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8425 - accuracy: 0.7045 - val_loss: 0.7963 - val_accuracy: 0.7262\nEpoch 16/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8239 - accuracy: 0.7146 - val_loss: 0.7945 - val_accuracy: 0.7252\nEpoch 17/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8118 - accuracy: 0.7171 - val_loss: 0.7950 - val_accuracy: 0.7280\nEpoch 18/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7960 - accuracy: 0.7230 - val_loss: 0.7832 - val_accuracy: 0.7291\nEpoch 19/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7874 - accuracy: 0.7285 - val_loss: 0.7608 - val_accuracy: 0.7343\nEpoch 20/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7738 - accuracy: 0.7332 - val_loss: 0.7606 - val_accuracy: 0.7415\nEpoch 21/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7671 - accuracy: 0.7348 - val_loss: 0.7311 - val_accuracy: 0.7492\nEpoch 22/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7566 - accuracy: 0.7404 - val_loss: 0.7354 - val_accuracy: 0.7473\nEpoch 23/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7469 - accuracy: 0.7441 - val_loss: 0.7232 - val_accuracy: 0.7538\nEpoch 24/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7420 - accuracy: 0.7460 - val_loss: 0.7558 - val_accuracy: 0.7389\nEpoch 25/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.7361 - accuracy: 0.7472 - val_loss: 0.7191 - val_accuracy: 0.7565\nEpoch 26/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7293 - accuracy: 0.7514 - val_loss: 0.7115 - val_accuracy: 0.7588\nEpoch 27/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7274 - accuracy: 0.7528 - val_loss: 0.7084 - val_accuracy: 0.7559\nEpoch 28/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.7193 - accuracy: 0.7543 - val_loss: 0.7122 - val_accuracy: 0.7603\nEpoch 29/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.7131 - accuracy: 0.7574 - val_loss: 0.7041 - val_accuracy: 0.7616\nEpoch 30/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.7097 - accuracy: 0.7582 - val_loss: 0.7308 - val_accuracy: 0.7552\nEpoch 31/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.7027 - accuracy: 0.7609 - val_loss: 0.7144 - val_accuracy: 0.7598\nEpoch 32/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6968 - accuracy: 0.7620 - val_loss: 0.7106 - val_accuracy: 0.7636\nEpoch 33/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6947 - accuracy: 0.7627 - val_loss: 0.7132 - val_accuracy: 0.7618\nEpoch 34/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6978 - accuracy: 0.7636 - val_loss: 0.7071 - val_accuracy: 0.7664\nEpoch 35/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6884 - accuracy: 0.7665 - val_loss: 0.6883 - val_accuracy: 0.7731\nEpoch 36/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6836 - accuracy: 0.7711 - val_loss: 0.6922 - val_accuracy: 0.7693\nEpoch 37/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6888 - accuracy: 0.7684 - val_loss: 0.7050 - val_accuracy: 0.7647\nEpoch 38/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6809 - accuracy: 0.7709 - val_loss: 0.6850 - val_accuracy: 0.7716\nEpoch 39/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6760 - accuracy: 0.7720 - val_loss: 0.6737 - val_accuracy: 0.7727\nEpoch 40/100\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.6791 - accuracy: 0.7714 - val_loss: 0.6735 - val_accuracy: 0.7723\nEpoch 41/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6709 - accuracy: 0.7752 - val_loss: 0.7108 - val_accuracy: 0.7586\nEpoch 42/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6723 - accuracy: 0.7734 - val_loss: 0.7270 - val_accuracy: 0.7611\nEpoch 43/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6654 - accuracy: 0.7745 - val_loss: 0.6459 - val_accuracy: 0.7826\nEpoch 44/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6616 - accuracy: 0.7776 - val_loss: 0.7039 - val_accuracy: 0.7672\nEpoch 45/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6627 - accuracy: 0.7774 - val_loss: 0.6463 - val_accuracy: 0.7859\nEpoch 46/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6556 - accuracy: 0.7788 - val_loss: 0.6680 - val_accuracy: 0.7777\nEpoch 47/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6550 - accuracy: 0.7790 - val_loss: 0.6525 - val_accuracy: 0.7863\nEpoch 48/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6549 - accuracy: 0.7791 - val_loss: 0.7113 - val_accuracy: 0.7692\nEpoch 49/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6482 - accuracy: 0.7824 - val_loss: 0.6454 - val_accuracy: 0.7834\nEpoch 50/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6513 - accuracy: 0.7823 - val_loss: 0.6874 - val_accuracy: 0.7776\nEpoch 51/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6538 - accuracy: 0.7823 - val_loss: 0.7067 - val_accuracy: 0.7674\nEpoch 52/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6538 - accuracy: 0.7820 - val_loss: 0.6757 - val_accuracy: 0.7746\nEpoch 53/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6491 - accuracy: 0.7830 - val_loss: 0.6863 - val_accuracy: 0.7751\nEpoch 54/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6482 - accuracy: 0.7834 - val_loss: 0.6904 - val_accuracy: 0.7826\nEpoch 55/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6476 - accuracy: 0.7844 - val_loss: 0.6793 - val_accuracy: 0.7795\nEpoch 56/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6431 - accuracy: 0.7859 - val_loss: 0.6716 - val_accuracy: 0.7765\nEpoch 57/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6393 - accuracy: 0.7846 - val_loss: 0.6967 - val_accuracy: 0.7798\nEpoch 58/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6370 - accuracy: 0.7872 - val_loss: 0.6362 - val_accuracy: 0.7910\nEpoch 59/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6357 - accuracy: 0.7869 - val_loss: 0.6583 - val_accuracy: 0.7822\nEpoch 60/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6390 - accuracy: 0.7880 - val_loss: 0.6533 - val_accuracy: 0.7875\nEpoch 61/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6374 - accuracy: 0.7878 - val_loss: 0.7210 - val_accuracy: 0.7590\nEpoch 62/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6414 - accuracy: 0.7881 - val_loss: 0.6807 - val_accuracy: 0.7782\nEpoch 63/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6321 - accuracy: 0.7903 - val_loss: 0.6690 - val_accuracy: 0.7844\nEpoch 64/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6289 - accuracy: 0.7900 - val_loss: 0.6293 - val_accuracy: 0.7954\nEpoch 65/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6375 - accuracy: 0.7902 - val_loss: 0.7027 - val_accuracy: 0.7705\nEpoch 66/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6319 - accuracy: 0.7903 - val_loss: 0.6839 - val_accuracy: 0.7841\nEpoch 67/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6303 - accuracy: 0.7883 - val_loss: 0.6580 - val_accuracy: 0.7870\nEpoch 68/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6375 - accuracy: 0.7887 - val_loss: 0.6700 - val_accuracy: 0.7858\nEpoch 69/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6311 - accuracy: 0.7917 - val_loss: 0.6351 - val_accuracy: 0.7898\nEpoch 70/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6324 - accuracy: 0.7908 - val_loss: 0.6696 - val_accuracy: 0.7855\nEpoch 71/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6327 - accuracy: 0.7897 - val_loss: 0.6597 - val_accuracy: 0.7773\nEpoch 72/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6303 - accuracy: 0.7915 - val_loss: 0.6857 - val_accuracy: 0.7747\nEpoch 73/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6324 - accuracy: 0.7906 - val_loss: 0.6890 - val_accuracy: 0.7716\nEpoch 74/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6303 - accuracy: 0.7893 - val_loss: 0.6736 - val_accuracy: 0.7876\nEpoch 75/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6305 - accuracy: 0.7915 - val_loss: 0.6945 - val_accuracy: 0.7797\nEpoch 76/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6261 - accuracy: 0.7936 - val_loss: 0.6361 - val_accuracy: 0.7958\nEpoch 77/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6290 - accuracy: 0.7890 - val_loss: 0.7529 - val_accuracy: 0.7505\nEpoch 78/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6277 - accuracy: 0.7923 - val_loss: 0.6983 - val_accuracy: 0.7761\nEpoch 79/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6254 - accuracy: 0.7925 - val_loss: 0.6571 - val_accuracy: 0.7858\nEpoch 80/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6252 - accuracy: 0.7911 - val_loss: 0.6540 - val_accuracy: 0.7854\nEpoch 81/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6313 - accuracy: 0.7902 - val_loss: 0.7033 - val_accuracy: 0.7695\nEpoch 82/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6311 - accuracy: 0.7897 - val_loss: 0.7078 - val_accuracy: 0.7621\nEpoch 83/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6287 - accuracy: 0.7917 - val_loss: 0.6390 - val_accuracy: 0.7892\nEpoch 84/100\n1563/1563 [==============================] - 12s 8ms/step - loss: 0.6296 - accuracy: 0.7900 - val_loss: 0.6906 - val_accuracy: 0.7770\nEpoch 85/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6240 - accuracy: 0.7905 - val_loss: 0.6612 - val_accuracy: 0.7830\nEpoch 86/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6207 - accuracy: 0.7951 - val_loss: 0.7037 - val_accuracy: 0.7694\nEpoch 87/100\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.6284 - accuracy: 0.7918 - val_loss: 0.7459 - val_accuracy: 0.7658\nEpoch 88/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6203 - accuracy: 0.7943 - val_loss: 0.6451 - val_accuracy: 0.7940\nEpoch 89/100\n1563/1563 [==============================] - 10s 7ms/step - loss: 0.6253 - accuracy: 0.7932 - val_loss: 0.6868 - val_accuracy: 0.7757\nEpoch 90/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6256 - accuracy: 0.7945 - val_loss: 0.6664 - val_accuracy: 0.7863\nEpoch 91/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6240 - accuracy: 0.7933 - val_loss: 0.7354 - val_accuracy: 0.7752\nEpoch 92/100\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.6233 - accuracy: 0.7916 - val_loss: 0.7051 - val_accuracy: 0.7732\nEpoch 93/100\n1563/1563 [==============================] - 14s 9ms/step - loss: 0.6277 - accuracy: 0.7909 - val_loss: 0.6483 - val_accuracy: 0.7896\nEpoch 94/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6276 - accuracy: 0.7913 - val_loss: 0.7401 - val_accuracy: 0.7571\nEpoch 95/100\n1563/1563 [==============================] - 11s 7ms/step - loss: 0.6272 - accuracy: 0.7938 - val_loss: 0.7447 - val_accuracy: 0.7546\nEpoch 96/100\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.6247 - accuracy: 0.7945 - val_loss: 0.7249 - val_accuracy: 0.7645\nEpoch 97/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6266 - accuracy: 0.7940 - val_loss: 0.8105 - val_accuracy: 0.7298\nEpoch 98/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6250 - accuracy: 0.7936 - val_loss: 0.7261 - val_accuracy: 0.7732\nEpoch 99/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6264 - accuracy: 0.7908 - val_loss: 0.6956 - val_accuracy: 0.7744\nEpoch 100/100\n1563/1563 [==============================] - 10s 6ms/step - loss: 0.6217 - accuracy: 0.7929 - val_loss: 0.7259 - val_accuracy: 0.7669\n"
    }
   ],
   "source": [
    "x_train=x_train.reshape((-1,32,32,3,1))\n",
    "x_test=x_test.reshape((-1,32,32,3,1))\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    h1=model1.fit(x_train1, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test1, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "    datagen.fit(x_train)\n",
    "    h1=model1.fit(datagen.flow(x_train.reshape(-1,32,32,3,1), y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),)\n",
    "h1=h1.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "tra=fig.add_subplot(121)\n",
    "tra.plot(h[\"accuracy\"], label=\"2D acc\", color=\"#B0E0E6\")\n",
    "tra.plot(h[\"val_accuracy\"], label=\"2D val_acc\", color=\"#FFDB99\")\n",
    "tra.plot(h1[\"accuracy\"], label=\"3D acc\", color=\"#379FAE\")\n",
    "tra.plot(h1[\"val_accuracy\"], label=\"3D val_acc\", color=\"#FFA500\")\n",
    "tra.legend()\n",
    "tra1=fig.add_subplot(121)\n",
    "tra1.plot(h[\"loss\"], label=\"2D acc\", color=\"#B0E0E6\")\n",
    "tra1.plot(h[\"val_loss\"], label=\"2D val_acc\", color=\"#FFDB99\")\n",
    "tra1.plot(h1[\"loss\"], label=\"3D acc\", color=\"#379FAE\")\n",
    "tra1.plot(h1[\"val_loss\"], label=\"3D val_acc\", color=\"#FFA500\")\n",
    "tra1.legend()\n",
    "fig.suptitle(\"Model metrics\")\n",
    "plt.savefig(\"resources/metrics.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"resources/2d.json\",\"w\")\n",
    "json.dump(h,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"resources/3d.json\",\"w\")\n",
    "json.dump(h1,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/c2d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"models/c3d.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"resources/2d.json\",\"r\")\n",
    "h=json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"resources/3d.json\",\"r\")\n",
    "h1=json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test.reshape((-1,32,32,3)), y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model1.evaluate(x_test.reshape((-1,32,32,3,1)), y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit9d2c145480604d93aae1bfd933aee138",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}